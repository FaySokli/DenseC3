init:
  doc_model: 'colbert-ir/colbertv2.0'
  tokenizer: ${model.init.doc_model}
  device: 'cuda'
  pooling_mode: 'mean'
  embedding_size: 768
  save_model: 'colbert'
  specialized_mode: 'blooms_top1AVG'
  max_tokenizer_length: 256
  normalize: False
  temperature: 1
adapters:
  num_experts_to_use: 6
  num_experts: 6
  residual: True
  latent_size: 192
  non_linearity: 'relu'
  use_adapters: True

continue_train: False